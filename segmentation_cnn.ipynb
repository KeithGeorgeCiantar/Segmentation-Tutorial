{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p9J8A3n_n_i1",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WUKA3jmC_k9K"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.rcParams['savefig.bbox'] = 'tight'\n",
    "\n",
    "import albumentations as A\n",
    "import graphviz\n",
    "import torch\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image, ImageDraw\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.io import read_image\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm import tqdm\n",
    "\n",
    "%pip install torchview\n",
    "from torchview import draw_graph\n",
    "\n",
    "graphviz.set_jupyter_format('png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yaQyU9Eon_i3"
   },
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "seed = 0\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mHp6wwzzn_i3",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# U-Net Model Architecture\n",
    "\n",
    "Here is some useful information about the U-Net model.\n",
    "* [U-Net: Convolutional Networks for Biomedical Image Segmentation, Ronneberger et al., 2015](https://link.springer.com/chapter/10.1007/978-3-319-24574-4_28)\n",
    "* [3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation](https://link.springer.com/chapter/10.1007/978-3-319-46723-8_49)\n",
    "* [The U-Net (actually) explained in 10 minutes](https://www.youtube.com/watch?v=NhdzGfB1q74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E6BJ2-bEn_i3"
   },
   "outputs": [],
   "source": [
    "# Code inspired by: https://towardsdatascience.com/cook-your-first-u-net-in-pytorch-b3297a844cf3\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_in=3, n_out=1, n_feat=8, kernel_size=3):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder_1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=n_in,\n",
    "                out_channels=n_feat,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=1,\n",
    "                padding='same',\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(\n",
    "                in_channels=n_feat,\n",
    "                out_channels=n_feat,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=1,\n",
    "                padding='same',\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.downsample_1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.encoder_2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=n_feat,\n",
    "                out_channels=n_feat * 2,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=1,\n",
    "                padding='same',\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(\n",
    "                in_channels=n_feat * 2,\n",
    "                out_channels=n_feat * 2,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=1,\n",
    "                padding='same',\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.downsample_2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.encoder_3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=n_feat * 2,\n",
    "                out_channels=n_feat * 4,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=1,\n",
    "                padding='same',\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(\n",
    "                in_channels=n_feat * 4,\n",
    "                out_channels=n_feat * 4,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=1,\n",
    "                padding='same',\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.downsample_3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.encoder_4 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=n_feat * 4,\n",
    "                out_channels=n_feat * 8,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=1,\n",
    "                padding='same',\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(\n",
    "                in_channels=n_feat * 8,\n",
    "                out_channels=n_feat * 8,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=1,\n",
    "                padding='same',\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.downsample_4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=n_feat * 8,\n",
    "                out_channels=n_feat * 16,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding='same',\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(\n",
    "                in_channels=n_feat * 16,\n",
    "                out_channels=n_feat * 16,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding='same',\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.upsample_1 = nn.ConvTranspose2d(\n",
    "            in_channels=n_feat * 16,\n",
    "            out_channels=n_feat * 8,\n",
    "            kernel_size=4,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "        )\n",
    "        self.decoder_1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=n_feat * 16,\n",
    "                out_channels=n_feat * 8,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=1,\n",
    "                padding='same',\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(\n",
    "                in_channels=n_feat * 8,\n",
    "                out_channels=n_feat * 8,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=1,\n",
    "                padding='same',\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.upsample_2 = nn.ConvTranspose2d(\n",
    "            in_channels=n_feat * 8,\n",
    "            out_channels=n_feat * 4,\n",
    "            kernel_size=4,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "        )\n",
    "        self.decoder_2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=n_feat * 8,\n",
    "                out_channels=n_feat * 4,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=1,\n",
    "                padding='same',\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(\n",
    "                in_channels=n_feat * 4,\n",
    "                out_channels=n_feat * 4,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=1,\n",
    "                padding='same',\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.upsample_3 = nn.ConvTranspose2d(\n",
    "            in_channels=n_feat * 4,\n",
    "            out_channels=n_feat * 2,\n",
    "            kernel_size=4,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "        )\n",
    "        self.decoder_3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=n_feat * 4,\n",
    "                out_channels=n_feat * 2,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=1,\n",
    "                padding='same',\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(\n",
    "                in_channels=n_feat * 2,\n",
    "                out_channels=n_feat * 2,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=1,\n",
    "                padding='same',\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.upsample_4 = nn.ConvTranspose2d(\n",
    "            in_channels=n_feat * 2,\n",
    "            out_channels=n_feat,\n",
    "            kernel_size=4,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "        )\n",
    "        self.decoder_4 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=n_feat * 2,\n",
    "                out_channels=n_feat,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=1,\n",
    "                padding='same',\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(\n",
    "                in_channels=n_feat,\n",
    "                out_channels=n_feat,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=1,\n",
    "                padding='same',\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # Output layer\n",
    "        self.output = nn.Conv2d(n_feat, n_out, stride=1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        enc_1 = self.encoder_1(x)\n",
    "        ds_1 = self.downsample_1(enc_1)\n",
    "\n",
    "        enc_2 = self.encoder_2(ds_1)\n",
    "        ds_2 = self.downsample_2(enc_2)\n",
    "\n",
    "        enc_3 = self.encoder_3(ds_2)\n",
    "        ds_3 = self.downsample_3(enc_3)\n",
    "\n",
    "        enc_4 = self.encoder_4(ds_3)\n",
    "        ds_4 = self.downsample_4(enc_4)\n",
    "\n",
    "        bottle = self.bottleneck(ds_4)\n",
    "\n",
    "        # Decoder\n",
    "        us_1 = self.upsample_1(bottle)\n",
    "        conc_1 = torch.cat([enc_4, us_1], dim=1)\n",
    "        dec_1 = self.decoder_1(conc_1)\n",
    "\n",
    "        us_2 = self.upsample_2(dec_1)\n",
    "        conc_2 = torch.cat([enc_3, us_2], dim=1)\n",
    "        dec_2 = self.decoder_2(conc_2)\n",
    "\n",
    "        us_3 = self.upsample_3(dec_2)\n",
    "        conc_3 = torch.cat([enc_2, us_3], dim=1)\n",
    "        dec_3 = self.decoder_3(conc_3)\n",
    "\n",
    "        us_4 = self.upsample_4(dec_3)\n",
    "        conc_4 = torch.cat([enc_1, us_4], dim=1)\n",
    "        dec_4 = self.decoder_4(conc_4)\n",
    "\n",
    "        # Output layer\n",
    "        out = self.output(dec_4)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dx7XzQqen_i4"
   },
   "outputs": [],
   "source": [
    "model = UNet()\n",
    "model_graph = draw_graph(model, input_size=(1, 3, 128, 128), device=torch.device('cuda'), graph_dir='TB')\n",
    "model_graph.resize_graph(1.5)\n",
    "model_graph.visual_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJJVDCw3n_i4",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data, Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "150qgYuDqMcL"
   },
   "source": [
    "## Download and unzip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BFi0HlwKpZ9k"
   },
   "outputs": [],
   "source": [
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "   !gdown 1uzaiglG7aOJae9EFy6Q0SSnWaNBoLNt5\n",
    "else:\n",
    "   !wget -O shapes_dataset.zip https://drive.usercontent.google.com/download?id=1uzaiglG7aOJae9EFy6Q0SSnWaNBoLNt5&export=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8BxQtrDbp4uh"
   },
   "outputs": [],
   "source": [
    "!unzip -q shapes_dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gzJIvEq0qK-b"
   },
   "outputs": [],
   "source": [
    "!rm -rf *__MACOSX*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "plagJ8hrn_i4"
   },
   "source": [
    "## Custom Dataset for Images and Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XiXRYieJ_k9O"
   },
   "outputs": [],
   "source": [
    "class ImagePairPreloadedDataset(Dataset):\n",
    "    def __init__(self, images_np, masks_np, transforms=None):\n",
    "        self.images_np = images_np\n",
    "        self.masks_np = masks_np\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.images_np[index]\n",
    "        y = self.masks_np[index]\n",
    "        y[y == 0] = 0.0\n",
    "        y[y == 255] = 1.0\n",
    "        if self.transforms is not None:\n",
    "            transformed = self.transforms(image=x, mask=y)\n",
    "            x = transformed['image']\n",
    "            y = transformed['mask']\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9C_bj9AHn_i5"
   },
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9RG9I2un_i5"
   },
   "source": [
    "### Preload data for faster processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nIGrF9Tnn_i5"
   },
   "outputs": [],
   "source": [
    "train_image_path = './shapes_dataset/train/images'\n",
    "train_mask_path = './shapes_dataset/train/masks'\n",
    "\n",
    "train_list = os.listdir(train_image_path)\n",
    "train_list_chosen = sorted([img for img in train_list if img.endswith('png')])\n",
    "\n",
    "train_image_list_paths = [os.path.join(train_image_path, img) for img in train_list_chosen]\n",
    "train_mask_list_paths = [os.path.join(train_mask_path, img.replace('image', 'mask')) for img in train_list_chosen]\n",
    "\n",
    "train_images_np = [read_image(train_image).numpy().transpose((1, 2, 0)).astype(np.float32) for train_image in train_image_list_paths]\n",
    "train_masks_np = [read_image(train_mask).numpy().transpose((1, 2, 0)).astype(np.float32) for train_mask in train_mask_list_paths]\n",
    "\n",
    "print('Total training images:', len(train_images_np))\n",
    "print('Total training masks:', len(train_masks_np))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ncz15F6Ln_i5"
   },
   "source": [
    "### Select data augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0fx2gYRrn_i5"
   },
   "outputs": [],
   "source": [
    "train_transform = A.Compose(\n",
    "    [\n",
    "        A.HorizontalFlip(),\n",
    "        A.VerticalFlip(),\n",
    "        A.RandomRotate90(),\n",
    "        A.ChannelShuffle(),\n",
    "        A.ToFloat(max_value=255),\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_seg_dataset = ImagePairPreloadedDataset(train_images_np, train_masks_np, transforms=train_transform)\n",
    "train_seg_dataloader = DataLoader(train_seg_dataset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8DaIRTSLn_i5"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 4, figsize=(10, 10))\n",
    "fig.subplots_adjust(hspace=0.1, wspace=0.05)\n",
    "\n",
    "for i, x in enumerate([0, 1, 2, 3]):\n",
    "    transformed_images = train_transform(image=train_images_np[x], mask=train_masks_np[x])\n",
    "\n",
    "    axs[i, 0].imshow(train_images_np[x] / 255.0)\n",
    "    axs[i, 0].set_title('Image' if i == 0 else '')\n",
    "    axs[i, 0].set_xticks([])\n",
    "    axs[i, 0].set_yticks([])\n",
    "\n",
    "    axs[i, 1].imshow(transformed_images['image'].numpy().transpose((1, 2, 0)))\n",
    "    axs[i, 1].set_title('Image Augmented' if i == 0 else '')\n",
    "    axs[i, 1].set_xticks([])\n",
    "    axs[i, 1].set_yticks([])\n",
    "\n",
    "    axs[i, 2].imshow(train_masks_np[x] / 255.0, cmap='gray')\n",
    "    axs[i, 2].set_title('Mask' if i == 0 else '')\n",
    "    axs[i, 2].set_xticks([])\n",
    "    axs[i, 2].set_yticks([])\n",
    "\n",
    "    axs[i, 3].imshow(transformed_images['mask'].numpy().transpose((1, 2, 0)), cmap='gray')\n",
    "    axs[i, 3].set_title('Mask Augmented' if i == 0 else '')\n",
    "    axs[i, 3].set_xticks([])\n",
    "    axs[i, 3].set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fcSyJdg2n_i6"
   },
   "source": [
    "## Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-2eUeVGvn_i6"
   },
   "outputs": [],
   "source": [
    "val_image_path = './shapes_dataset/val/images'\n",
    "val_mask_path = './shapes_dataset/val/masks'\n",
    "\n",
    "val_list = os.listdir(val_image_path)\n",
    "val_list_chosen = sorted([img for img in val_list if img.endswith('png')])\n",
    "\n",
    "val_image_list_paths = [os.path.join(val_image_path, img) for img in val_list_chosen]\n",
    "val_mask_list_paths = [os.path.join(val_mask_path, img.replace('image', 'mask')) for img in val_list_chosen]\n",
    "\n",
    "val_images_np = [read_image(val_image).numpy().transpose((1, 2, 0)).astype(np.float32) for val_image in val_image_list_paths]\n",
    "val_masks_np = [read_image(val_mask).numpy().transpose((1, 2, 0)).astype(np.float32) for val_mask in val_mask_list_paths]\n",
    "\n",
    "print('Total validation images:', len(val_images_np))\n",
    "print('Total validation masks:', len(val_masks_np))\n",
    "\n",
    "val_transform = A.Compose(\n",
    "    [\n",
    "        A.ToFloat(max_value=255),\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_seg_dataset = ImagePairPreloadedDataset(val_images_np, val_masks_np, transforms=val_transform)\n",
    "val_seg_dataloader = DataLoader(val_seg_dataset, batch_size=64, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ze-MyxCo_k9P",
    "jp-MarkdownHeadingCollapsed": true,
    "outputId": "059d673f-3fe4-4ae4-e0c9-7aed28b70933"
   },
   "source": [
    "# Loss function\n",
    "\n",
    "## Binary Cross Entropy Loss\n",
    "<img src='https://miro.medium.com/v2/resize:fit:4800/format:webp/1*QohPFy6wBfbjK5VUWxlyoA.png' alt='Binary Cross Entropy Loss' width='400'/>\n",
    "\n",
    "## Dice Score Coefficient\n",
    "<img src='https://miro.medium.com/v2/resize:fit:720/format:webp/1*tSqwQ9tvLmeO9raDqg3i-w.png' alt='Dice Score Coefficient' width='400'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uh6aSZGGHTcS"
   },
   "outputs": [],
   "source": [
    "class BCEDiceLoss(nn.Module):\n",
    "    def __init__(self, eps=1e-9, weight_dice=1.0, weight_bce=1.0):\n",
    "        super(BCEDiceLoss, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.weight_dice = weight_dice\n",
    "        self.weight_bce = weight_bce\n",
    "        self.bce_loss = nn.BCEWithLogitsLoss(reduction='none')\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        # Take mean Binary Cross Entropy per image and then per batch\n",
    "        bce = self.bce_loss(y_pred, y_true).mean(dim=(-1, -2)).mean()\n",
    "\n",
    "        # Sigmoid is needed to transform the model output into binary\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "\n",
    "        # Intersection |Y_pred âˆ© Y_true| of the predicted mask and the real mask\n",
    "        intersection = y_pred * y_true\n",
    "        intersection_sum_per_image = intersection.sum(dim=(-1, -2))  # Intersection sum per image\n",
    "\n",
    "        # Denominator sum |Y_pred| + |Y_true|\n",
    "        sum_of_sum_per_image = y_pred.sum(dim=(-1, -2)) + y_true.sum(dim=(-1, -2))  # Sum the predicted masks and the real masks\n",
    "\n",
    "        # Dice score coefficient per image\n",
    "        dice_per_image = (2 * intersection_sum_per_image + self.eps) / (sum_of_sum_per_image + self.eps)\n",
    "        dice_loss_per_image = 1 - dice_per_image\n",
    "\n",
    "        # Mean of dice scores across batch\n",
    "        dice = dice_loss_per_image.mean()\n",
    "\n",
    "        return bce * self.weight_bce + dice * self.weight_dice, dice, bce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "onCi85V-n_i6",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F-CXrcImn_i6"
   },
   "outputs": [],
   "source": [
    "def plot_batch(image, mask, output, save_path):\n",
    "    fig, axs = plt.subplots(3, 1, figsize=(16, 8))\n",
    "    fig.subplots_adjust(hspace=0.2, wspace=0.075)\n",
    "\n",
    "    axs = axs.ravel()\n",
    "\n",
    "    image_grid = make_grid(image, nrow=16, pad_value=0)\n",
    "    axs[0].imshow(np.transpose(image_grid, (1, 2, 0)))\n",
    "    axs[0].set_title('Input')\n",
    "    axs[0].set_xticks([])\n",
    "    axs[0].set_yticks([])\n",
    "\n",
    "    mask_grid = make_grid(mask, nrow=16, pad_value=1)\n",
    "    axs[1].imshow(np.transpose(mask_grid, (1, 2, 0)))\n",
    "    axs[1].set_title('Real Mask')\n",
    "    axs[1].set_xticks([])\n",
    "    axs[1].set_yticks([])\n",
    "\n",
    "    output_grid = make_grid(output, nrow=16, pad_value=1)\n",
    "    axs[2].imshow(np.transpose(output_grid, (1, 2, 0)))\n",
    "    axs[2].set_title('Predicted Mask')\n",
    "    axs[2].set_xticks([])\n",
    "    axs[2].set_yticks([])\n",
    "\n",
    "    plt.savefig(save_path, bbox_inches='tight', pad_inches=0.05, dpi=100, format='png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wf2wZzc-_k9Q"
   },
   "outputs": [],
   "source": [
    "epochs = 12\n",
    "width = 16\n",
    "\n",
    "checkpoint_dir = f'checkpoints_seg_width_{width}_epochs_{epochs}'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = UNet(n_feat=width, kernel_size=3)\n",
    "model.to(device)\n",
    "\n",
    "criterion = BCEDiceLoss(weight_dice=1.0, weight_bce=1.0)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_running_loss = 0.0\n",
    "\n",
    "    train_progress_bar = tqdm(train_seg_dataloader, desc=f'Epoch {epoch+1}/{epochs}', unit='batch')\n",
    "\n",
    "    for x, y in train_progress_bar:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out = model(x)\n",
    "\n",
    "        loss, dice, bce = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_running_loss += loss.item()\n",
    "        train_progress_bar.set_postfix(loss=loss.item(), dice_loss=dice.item(), bce_loss=bce.item())\n",
    "\n",
    "    val_running_loss = 0.0\n",
    "    model.eval()\n",
    "\n",
    "    val_progress_bar = tqdm(val_seg_dataloader, desc=f'Epoch {epoch+1}/{epochs}', unit='batch')\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for vx, vy in val_progress_bar:\n",
    "            vx = vx.to(device)\n",
    "            vy = vy.to(device)\n",
    "\n",
    "            vout = model(vx)\n",
    "\n",
    "            vloss, vdice, vbce = criterion(vout, vy)\n",
    "            val_running_loss += vloss.item()\n",
    "            val_progress_bar.set_postfix(loss=vloss.item(), dice_loss=vdice.item(), bce_loss=vbce.item())\n",
    "\n",
    "    print(\n",
    "        '\\nDice+BCE Loss train: {}, validation: {}'.format(\n",
    "            train_running_loss / len(train_seg_dataloader),\n",
    "            val_running_loss / len(val_seg_dataloader),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    scheduler.step(val_running_loss / len(val_seg_dataloader))\n",
    "\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model': model,\n",
    "        'optimizer': optimizer,\n",
    "        'lr_sched': scheduler,\n",
    "    }\n",
    "\n",
    "    if epoch + 1 > 45 or epoch < 15:\n",
    "        torch.save(checkpoint, os.path.join(checkpoint_dir, f'checkpoint_{epoch+1}.pth'))\n",
    "\n",
    "    plot_batch(\n",
    "        vx.detach().cpu(),\n",
    "        vy.detach().cpu(),\n",
    "        torch.sigmoid(vout.detach().cpu()),\n",
    "        os.path.join(checkpoint_dir, f'sample_{epoch}.png'),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZqnfr_wn_i7",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Test with custom image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L_8ACTtpn_i7"
   },
   "outputs": [],
   "source": [
    "def draw_circle(draw_image, centre, radius, colour):\n",
    "    draw_image.ellipse(\n",
    "        (\n",
    "            centre[0] - radius,\n",
    "            centre[1] - radius,\n",
    "            centre[0] + radius,\n",
    "            centre[1] + radius,\n",
    "        ),\n",
    "        fill=colour,\n",
    "    )\n",
    "\n",
    "\n",
    "def draw_ellipse(draw_image, centre, radius_1, radius_2, colour):\n",
    "    draw_image.ellipse(\n",
    "        (\n",
    "            centre[0] - radius_1,\n",
    "            centre[1] - radius_2,\n",
    "            centre[0] + radius_1,\n",
    "            centre[1] + radius_2,\n",
    "        ),\n",
    "        fill=colour,\n",
    "    )\n",
    "\n",
    "\n",
    "def draw_rectangle(draw_image, top_left, bottom_right, colour):\n",
    "    draw_image.rectangle([top_left, bottom_right], fill=colour)\n",
    "\n",
    "\n",
    "def draw_square(draw_image, centre, radius, rotation, colour):\n",
    "    draw_image.regular_polygon((centre, radius), n_sides=4, rotation=rotation, fill=colour)\n",
    "\n",
    "\n",
    "def draw_pentagon(draw_image, centre, radius, rotation, colour):\n",
    "    draw_image.regular_polygon((centre, radius), n_sides=5, rotation=rotation, fill=colour)\n",
    "\n",
    "\n",
    "def draw_hexagon(draw_image, centre, radius, rotation, colour):\n",
    "    draw_image.regular_polygon((centre, radius), n_sides=6, rotation=rotation, fill=colour)\n",
    "\n",
    "\n",
    "def draw_triangle(draw_image, draw_mask, centre, radius, rotation, colour):\n",
    "    draw_image.regular_polygon((centre, radius), n_sides=3, rotation=rotation, fill=colour)\n",
    "    draw_mask.regular_polygon((centre, radius), n_sides=3, rotation=rotation, fill=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DbEcRVVVn_i7"
   },
   "outputs": [],
   "source": [
    "def plot_two_images(image_1, image_2, title_1, title_2, cmap_1, cmap_2):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(7, 5))\n",
    "    axs = axs.ravel()\n",
    "\n",
    "    axs[0].imshow(image_1, cmap=cmap_1)\n",
    "    axs[0].set_title(title_1)\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    axs[1].imshow(image_2, cmap=cmap_2)\n",
    "    axs[1].set_title(title_2)\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GnwFAdL8n_i8"
   },
   "source": [
    "## Create a custom image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n8VBSm6un_i8"
   },
   "outputs": [],
   "source": [
    "image_size = (128, 128)\n",
    "\n",
    "image = Image.new('RGB', image_size, (255, 255, 255))\n",
    "mask = Image.new('L', image_size, 0)\n",
    "\n",
    "draw_image = ImageDraw.Draw(image)\n",
    "draw_mask = ImageDraw.Draw(mask)\n",
    "\n",
    "# Draw shapes\n",
    "draw_circle(draw_image, centre=(40, 40), radius=40, colour=(200, 1, 1))\n",
    "draw_ellipse(draw_image, centre=(90, 100), radius_1=20, radius_2=10, colour=(1, 200, 1))\n",
    "draw_rectangle(draw_image, top_left=(10, 10), bottom_right=(90, 50), colour=(1, 1, 200))\n",
    "draw_square(draw_image, centre=(67, 67), radius=50, rotation=30, colour=(200, 200, 1))\n",
    "draw_pentagon(draw_image, centre=(27, 87), radius=20, rotation=30, colour=(100, 200, 1))\n",
    "draw_hexagon(draw_image, centre=(27, 97), radius=20, rotation=30, colour=(200, 100, 1))\n",
    "\n",
    "# Draw triangle\n",
    "draw_triangle(\n",
    "    draw_image,\n",
    "    draw_mask,\n",
    "    centre=(70, 70),\n",
    "    radius=60,\n",
    "    rotation=95,\n",
    "    colour=(100, 100, 200),\n",
    ")\n",
    "\n",
    "image_np = np.array(image)\n",
    "mask_np = np.array(mask)\n",
    "\n",
    "plot_two_images(image_np, mask_np, 'Image', 'Mask', None, 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cmsNSW8ln_i8"
   },
   "source": [
    "## Test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h4tg-OoKn_i8"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = torch.load(os.path.join('checkpoints_seg_width_16_epochs_12', 'checkpoint_12.pth'))['model']\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "image_pt = torch.tensor(image_np.transpose((2, 0, 1)) / 255.0, dtype=torch.float32).to(device).unsqueeze(0)\n",
    "predicted_mask = model(image_pt)\n",
    "predicted_mask_np = torch.sigmoid(predicted_mask.cpu().detach()).numpy().squeeze()\n",
    "\n",
    "plot_two_images(mask_np, predicted_mask_np, 'Mask', 'Predicted', 'gray', 'gray')\n",
    "\n",
    "dice = 2 * np.sum(mask_np * predicted_mask_np) / (np.sum(mask_np) + np.sum(predicted_mask_np))\n",
    "print('Dice Score Coefficient', dice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLBN2M-en_i8",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Visualising features and filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZeuYPDQKn_i8"
   },
   "outputs": [],
   "source": [
    "activation = {}\n",
    "\n",
    "\n",
    "def get_activation(name):\n",
    "    def hook(model, x, y):\n",
    "        activation[name] = y.detach()\n",
    "\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VdVPTeGkn_i8"
   },
   "outputs": [],
   "source": [
    "model.encoder_1.register_forward_hook(get_activation('encoder_1'))\n",
    "model.encoder_2.register_forward_hook(get_activation('encoder_2'))\n",
    "model.encoder_3.register_forward_hook(get_activation('encoder_3'))\n",
    "model.encoder_4.register_forward_hook(get_activation('encoder_4'))\n",
    "model.bottleneck.register_forward_hook(get_activation('bottleneck'))\n",
    "model.decoder_1.register_forward_hook(get_activation('decoder_1'))\n",
    "model.decoder_2.register_forward_hook(get_activation('decoder_2'))\n",
    "model.decoder_3.register_forward_hook(get_activation('decoder_3'))\n",
    "model.decoder_4.register_forward_hook(get_activation('decoder_4'))\n",
    "model.output.register_forward_hook(get_activation('output'))\n",
    "predicted_mask = model(image_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W9jglyTtn_i8"
   },
   "outputs": [],
   "source": [
    "def plot_features(features, layer_title, columns=8, cmap='Reds'):\n",
    "    rows = features.size(0) // columns\n",
    "\n",
    "    width = columns * 2\n",
    "    height = rows * 2.22\n",
    "\n",
    "    fig, axs = plt.subplots(rows, columns, figsize=(width, height))\n",
    "    fig.subplots_adjust(hspace=0.01, wspace=0.01)\n",
    "\n",
    "    axs = axs.ravel() if len(fig.get_axes()) > 1 else [axs]\n",
    "\n",
    "    for idx in range(len(axs)):\n",
    "        axs[idx].imshow(features[idx].cpu().detach().numpy(), cmap=cmap)\n",
    "        axs[idx].set_xticks([])\n",
    "        axs[idx].set_yticks([])\n",
    "    fig.suptitle(\n",
    "        'Block: ' + layer_title + ' | Feature dimensions: ' + str(features.cpu().detach().numpy().shape),\n",
    "        fontsize=2 * (columns) if columns > 1 else 12,\n",
    "    )\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ctpn_Qngn_i8"
   },
   "outputs": [],
   "source": [
    "def plot_filters(filters, layer_title, inner_layer_title, cmap='Reds', has_been_transposed=False):\n",
    "    rows = filters.size(1)\n",
    "    columns = filters.size(0)\n",
    "\n",
    "    width = columns\n",
    "    height = rows\n",
    "\n",
    "    fig, axs = plt.subplots(rows, columns, figsize=(width, height))\n",
    "    fig.subplots_adjust(hspace=0.01, wspace=0.01)\n",
    "\n",
    "    for r in range(rows):\n",
    "        for c in range(columns):\n",
    "            if rows == 1:\n",
    "                curr_axs = axs[c]\n",
    "            elif columns == 1:\n",
    "                curr_axs = axs[r]\n",
    "            else:\n",
    "                curr_axs = axs[r, c]\n",
    "\n",
    "            curr_axs.imshow(filters[c][r].cpu().detach().numpy(), cmap=cmap)\n",
    "            curr_axs.set_xticks([])\n",
    "            curr_axs.set_yticks([])\n",
    "    filter_dims = str(filters.cpu().detach().numpy().shape) if not has_been_transposed else str(filters.transpose(1, 0).cpu().detach().numpy().shape)\n",
    "    fig.suptitle(\n",
    "        'Block: ' + layer_title + ' | Inner layer: ' + inner_layer_title + ' | Filter dimensions: ' + filter_dims,\n",
    "        fontsize=2 * (columns) if columns < 16 else columns,\n",
    "        y=0.99,\n",
    "    )\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSsBes3tn_i8"
   },
   "source": [
    "## Encoder features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TbEfS9Ttn_i8"
   },
   "outputs": [],
   "source": [
    "layer = 'encoder_1'\n",
    "features = activation[layer].squeeze()\n",
    "plot_features(features, layer_title=layer, columns=8, cmap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5IVhfPPon_i9"
   },
   "outputs": [],
   "source": [
    "layer = 'encoder_2'\n",
    "features = activation[layer].squeeze()\n",
    "plot_features(features, layer_title=layer, columns=8, cmap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RuA1_9Agn_i9"
   },
   "outputs": [],
   "source": [
    "layer = 'encoder_3'\n",
    "features = activation[layer].squeeze()\n",
    "plot_features(features, layer_title=layer, columns=16, cmap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X2IamHedn_i9"
   },
   "outputs": [],
   "source": [
    "layer = 'encoder_4'\n",
    "features = activation[layer].squeeze()\n",
    "plot_features(features, layer_title=layer, columns=16, cmap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p4I_2xDFn_i9"
   },
   "outputs": [],
   "source": [
    "layer = 'bottleneck'\n",
    "features = activation[layer].squeeze()\n",
    "plot_features(features, layer_title=layer, columns=32, cmap='Reds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2VuEfpMSn_i9"
   },
   "source": [
    "## Decoder features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wn42NoAln_i9"
   },
   "outputs": [],
   "source": [
    "layer = 'decoder_1'\n",
    "features = activation[layer].squeeze()\n",
    "plot_features(features, layer_title=layer, columns=16, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RANKX64Ln_i9"
   },
   "outputs": [],
   "source": [
    "layer = 'decoder_2'\n",
    "features = activation[layer].squeeze()\n",
    "plot_features(features, layer_title=layer, columns=16, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yv2nLJRFn_i9"
   },
   "outputs": [],
   "source": [
    "layer = 'decoder_3'\n",
    "features = activation[layer].squeeze()\n",
    "plot_features(features, layer_title=layer, columns=8, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l_Cc1A6Sn_i9"
   },
   "outputs": [],
   "source": [
    "layer = 'decoder_4'\n",
    "features = activation[layer].squeeze()\n",
    "plot_features(features, layer_title=layer, columns=8, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R8i7l18Nn_i9"
   },
   "outputs": [],
   "source": [
    "layer = 'output'\n",
    "features = activation[layer].squeeze(0)\n",
    "plot_features(features, layer_title=layer, columns=1, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5tQB9fzyn_i-"
   },
   "outputs": [],
   "source": [
    "layer = 'output'\n",
    "features = torch.sigmoid(activation[layer].squeeze(0))\n",
    "plot_features(features, layer_title=layer + ' + sigmoid', columns=1, cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EaugS-Rtn_i-"
   },
   "source": [
    "## Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_AYFBshIn_i-"
   },
   "outputs": [],
   "source": [
    "w_encoder_1_1 = model.encoder_1[0].weight.detach()\n",
    "w_encoder_1_2 = model.encoder_1[2].weight.detach()\n",
    "w_encoder_2_1 = model.encoder_2[0].weight.detach()\n",
    "w_encoder_2_2 = model.encoder_2[2].weight.detach()\n",
    "w_encoder_3_1 = model.encoder_3[0].weight.detach()\n",
    "w_encoder_3_2 = model.encoder_3[2].weight.detach()\n",
    "w_encoder_4_1 = model.encoder_4[0].weight.detach()\n",
    "w_encoder_4_2 = model.encoder_4[2].weight.detach()\n",
    "w_bottleneck_1 = model.bottleneck[0].weight.detach()\n",
    "w_bottleneck_2 = model.bottleneck[2].weight.detach()\n",
    "\n",
    "w_decoder_1_1 = model.decoder_1[0].weight.detach()\n",
    "w_decoder_1_2 = model.decoder_1[2].weight.detach()\n",
    "w_decoder_2_1 = model.decoder_2[0].weight.detach()\n",
    "w_decoder_2_2 = model.decoder_2[2].weight.detach()\n",
    "w_decoder_3_1 = model.decoder_3[0].weight.detach()\n",
    "w_decoder_3_2 = model.decoder_3[2].weight.detach()\n",
    "w_decoder_4_1 = model.decoder_4[0].weight.detach()\n",
    "w_decoder_4_2 = model.decoder_4[2].weight.detach()\n",
    "w_output = model.output.weight.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Iuze013n_i-"
   },
   "outputs": [],
   "source": [
    "plot_filters(w_encoder_1_1, 'encoder_1', 'conv_1', cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gobb4-5Jn_i-"
   },
   "outputs": [],
   "source": [
    "plot_filters(w_encoder_1_2, 'encoder_1', 'conv_2', cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JHwrqJdpn_i-"
   },
   "outputs": [],
   "source": [
    "plot_filters(w_encoder_2_1, 'encoder_2', 'conv_1', cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qGOC8MPnn_i-"
   },
   "outputs": [],
   "source": [
    "plot_filters(w_decoder_4_2, 'decoder_4', 'conv_2', cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IzeLxyB1n_i-"
   },
   "outputs": [],
   "source": [
    "plot_filters(w_output.transpose(1, 0), 'output', 'conv', cmap='gray', has_been_transposed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
